# cp .env.example .env
# Edit your .env file with your own values
# Don't commit your .env file to git/push to GitHub!
# Don't modify/delete .env.example unless adding extensions to the project
# which require new variable to be added to the .env file

# INSTANCE CONFIG
AGENT_NAME=Agent-LLM

# Set objective and initial task
OBJECTIVE=Solve world hunger
INITIAL_TASK=Develop a task list

# AI_PROVIDER can currently be openai, llama (local only), or oobabooga (local only)
AI_PROVIDER=openai

# VECTORDB_PROVIDER can currently be pinecone or faiss (local only)
VECTORDB_PROVIDER=pinecone

# EMBEDDING can either be openai or longformer (local only)
EMBEDDING=openai

# AI Model can either be gpt-3.5-turbo, gpt-4, text-davinci-003, vicuna, etc
# This determines what prompts are given to the AI and determines which model is used for certain providers.
AI_MODEL=gpt-3.5-turbo

# Temperature for AI, leave default if you don't know what this is
AI_TEMPERATURE=0.4

# Extensions settings

# OpenAI settings for running OpenAI AI_PROVIDER
OPENAI_API_KEY=

# Pinecone settings for running Pinecone VECTORDB_PROVIDER
PINECONE_API_KEY=
PINECONE_ENVIRONMENT=us-east1-gcp
TABLE_NAME=your-table-name

# List additional extensions to load (except .env.example!)
DOTENV_EXTENSIONS=
# Set to true to enable command line args support
ENABLE_COMMAND_LINE_ARGS=false
